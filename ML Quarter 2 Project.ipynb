{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00000-a6014a96-a961-4af3-ac18-f036ad390a4b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "dc0497e8",
    "execution_start": 1641973763532,
    "execution_millis": 4242,
    "deepnote_cell_type": "code"
   },
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import svm, datasets\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.base import BaseEstimator, ClassifierMixin\nfrom sklearn.utils.validation import check_X_y, check_array, check_is_fitted\nfrom sklearn.utils.multiclass import unique_labels\nimport time\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00001-1868df77-dada-43c6-b3d6-b36b53097dc1",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d278a1fa",
    "execution_start": 1641965684778,
    "execution_millis": 56,
    "deepnote_cell_type": "code"
   },
   "source": "class ANNSVM(BaseEstimator, ClassifierMixin):\n\n    def __init__(self, hidden_layer_sizes=(100,), activation='relu', solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', \\\n                learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, \\\n                momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, \\\n                n_iter_no_change=10, max_fun=15000):\n        self.NNclf = MLPClassifier(\n            hidden_layer_sizes=hidden_layer_sizes,\n            activation=activation,\n            solver=solver,\n            alpha=alpha,\n            batch_size=batch_size,\n            learning_rate=learning_rate,\n            learning_rate_init=learning_rate_init,\n            power_t=power_t,\n            max_iter=max_iter,\n            shuffle=shuffle,\n            random_state=random_state,\n            tol=tol,\n            verbose=verbose,\n            warm_start=warm_start,\n            momentum=momentum,\n            nesterovs_momentum=nesterovs_momentum,\n            early_stopping=early_stopping,\n            validation_fraction=validation_fraction,\n            beta_1=beta_1,\n            beta_2=beta_2,\n            epsilon=epsilon,\n            n_iter_no_change=n_iter_no_change,\n            max_fun=max_fun,\n        )\n        self.activation = activation\n        self.solver = solver\n        self.alpha = alpha\n        self.batch_size = batch_size\n        self.learning_rate = learning_rate\n        self.learning_rate_init = learning_rate_init\n        self.power_t = power_t\n        self.max_iter = max_iter\n        self.hidden_layer_sizes = hidden_layer_sizes\n        self.shuffle = shuffle\n        self.random_state = random_state\n        self.tol = tol\n        self.verbose = verbose\n        self.warm_start = warm_start\n        self.momentum = momentum\n        self.nesterovs_momentum = nesterovs_momentum\n        self.early_stopping = early_stopping\n        self.validation_fraction = validation_fraction\n        self.beta_1 = beta_1\n        self.beta_2 = beta_2\n        self.epsilon = epsilon\n        self.n_iter_no_change = n_iter_no_change\n        self.max_fun = max_fun\n\n    def fit(self, X, y):\n        X, y = check_X_y(X, y)\n        self.classes_ = unique_labels(y)\n\n        self.X_ = X\n        self.y_ = y\n\n        # seperate data into the different subsets based on classes\n        self.__create_subsets()\n\n        # Creates and fits the svms used for ovo\n        self.__create_fit_svms()\n\n        # Creates and fits the ANN used for weighting each svm\n        self.__create_fit_ANN()\n\n        return self\n\n    def predict(self, X):\n        check_is_fitted(self)\n        X = check_array(X)\n\n        # Test on testing set\n        NNX_test = None\n\n        for _ in range(len(X)):\n            result = []\n            # get probability values from each svm for the X value\n            for i in range(len(self.classes_)):\n                for j in range(i+1, len(self.classes_)):\n                    probs = self.svms[f'{i}{j}'].predict_proba([X[_]])\n                    for prob in probs:\n                        if prob[0] > prob[1]:\n                            result.append(-prob[0])\n                        else:\n                            result.append(prob[1])\n            # create the input set for the ANN\n            if _ == 0:\n                NNX_test = np.array([result])\n            else:\n                NNX_test = np.append(NNX_test, np.array([result]), axis=0)\n\n        predictions = self.NNclf.predict(NNX_test)\n        \n        return predictions\n\n    # Creates subsets of X with each subset only containing one class\n    # Uses the training X and y\n    def __create_subsets(self):\n        # seperate data into the different subsets based on classes\n        self.X_trains = {value:np.array([]) for value in self.classes_}\n        for i in range(len(self.X_)):\n            if self.X_trains[self.y_[i]].size == 0:\n                self.X_trains[self.y_[i]] = np.array([self.X_[i]])\n            else:\n                self.X_trains[self.y_[i]] = np.append(self.X_trains[self.y_[i]], np.array([self.X_[i]]), axis = 0)\n\n    # Creates and fits svms for each pair of classes (the svms for ovo)\n    def __create_fit_svms(self):\n        # The svms for each pair of classes\n        self.svms = {}\n        for i in self.classes_:\n            for j in self.classes_:\n                if i < j:\n                    temp_clf = svm.SVC(probability=True)\n                    self.svms[f'{i}{j}'] = temp_clf\n\n        # fit each svm with the corresponding pair of subdatasets\n        for i in range(len(self.classes_)):\n            for j in range(i+1, len(self.classes_)):\n                curr_X_train = np.append(self.X_trains[i], self.X_trains[j], axis=0)\n                curr_y_train = np.append(np.full(len(self.X_trains[i]), i), np.full(len(self.X_trains[j]), j))\n                self.svms[f'{i}{j}'].fit(curr_X_train, curr_y_train)\n\n    # Creates and fits an ANN classifier\n    # ANN Input: the probability value from each svm. \n    # For each svm, chooses the larger probability of the two\n    # Makes negative if probability in index 0\n    # ANN Output: class value\n    # Uses the training X and y\n    def __create_fit_ANN(self):\n        # Create data for NN\n        NNX_train = None\n\n        for _ in range(len(self.X_)):\n            result = []\n            for i in range(len(self.classes_)):\n                for j in range(i+1, len(self.classes_)):\n                    probs = self.svms[f'{i}{j}'].predict_proba([self.X_[_]])\n                    for prob in probs:\n                        if prob[0] > prob[1]:\n                            result.append(-prob[0])\n                        else:\n                            result.append(prob[1])\n            if _ == 0:\n                NNX_train = np.array([result])\n            else:\n                NNX_train = np.append(NNX_train, np.array([result]), axis=0)\n\n        self.NNclf.fit(NNX_train, self.y_)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00007-c35bc841-8572-4a7f-b158-5e17e8dd3fa5",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "8862175f",
    "execution_start": 1641965684838,
    "execution_millis": 52,
    "deepnote_output_heights": [
     78.75
    ],
    "deepnote_cell_type": "code"
   },
   "source": "class KNNSVM(BaseEstimator, ClassifierMixin):\n\n    def __init__(self, K=5):\n        self.K = K;\n\n    def fit(self, X, y):\n        X, y = check_X_y(X, y)\n        self.classes_ = unique_labels(y)\n\n        self.X_ = X\n        self.y_ = y\n\n        # seperate data into the different subsets based on classes\n        self.__create_subsets()\n\n        # Creates and fits the svms used for ovo\n        self.__create_fit_svms()\n\n        # Determines the class centers\n        self.__determine_class_centers()\n\n        return self\n\n    def predict(self, X):\n        check_is_fitted(self)\n        X = check_array(X)\n\n        predictions = self.__KNNpredict(X) #self.NNclf.predict(NNX_test)\n        \n        return predictions\n\n    # Creates subsets of X with each subset only containing one class\n    # Uses the training X and y\n    def __create_subsets(self):\n        # seperate data into the different subsets based on classes\n        self.X_trains = {value:np.array([]) for value in self.classes_}\n        for i in range(len(self.X_)):\n            if self.X_trains[self.y_[i]].size == 0:\n                self.X_trains[self.y_[i]] = np.array([self.X_[i]])\n            else:\n                self.X_trains[self.y_[i]] = np.append(self.X_trains[self.y_[i]], np.array([self.X_[i]]), axis = 0)\n\n    # Creates and fits svms for each pair of classes (the svms for ovo)\n    def __create_fit_svms(self):\n        # The svms for each pair of classes\n        self.svms = {}\n        for i in self.classes_:\n            for j in self.classes_:\n                if i < j:\n                    temp_clf = svm.SVC(probability=True)\n                    self.svms[f'{i}{j}'] = temp_clf\n\n        # fit each svm with the corresponding pair of subdatasets\n        for i in range(len(self.classes_)):\n            for j in range(i+1, len(self.classes_)):\n                curr_X_train = np.append(self.X_trains[i], self.X_trains[j], axis=0)\n                curr_y_train = np.append(np.full(len(self.X_trains[i]), i), np.full(len(self.X_trains[j]), j))\n                self.svms[f'{i}{j}'].fit(curr_X_train, curr_y_train)\n\n    # Calculates the class centers of the training data\n    def __determine_class_centers(self):\n        self.class_centers = {class_value:[] for class_value in self.X_trains}\n        for classes in self.X_trains:\n            subset = self.X_trains[classes]\n            center = [0 for i in range(len(subset[0]))]\n            for i in range(len(subset)):\n                for j in range(len(subset[i])):\n                    center[j] += subset[i][j]\n            self.class_centers[classes] = [value/len(subset) for value in center]\n\n    # classifies the test data based on the SVMs and KNNs & class centers\n    def __KNNpredict(self, X):\n        predictions = []\n        for i in range(len(X)):\n            test_sample = X[i]\n            # calculate distance to centers\n            distance_to_centers = {class_value:0 for class_value in self.class_centers}\n            for class_value in distance_to_centers:\n                distance_to_center = self.__distance(test_sample, self.class_centers[class_value])\n                distance_to_centers[class_value] = distance_to_center\n            # calculate average distance to KNN of each class\n            avg_dist_to_KNN = {class_value:0 for class_value in self.X_trains}\n            for class_value in avg_dist_to_KNN:\n                subset = self.X_trains[class_value]\n                distances_to_subset = np.sort(np.array([self.__distance(test_sample, value) for value in subset]))\n                distances_to_KNN = distances_to_subset[:self.K]\n                avg_value = np.average(distances_to_KNN)\n                avg_dist_to_KNN[class_value] = avg_value\n            \n            # calculate score matrix and multiply weight\n            score_matrix  = [[0]*len(self.classes_) for i in range(len(self.classes_))]\n            for j in range(len(score_matrix)):\n                for j_star in range(len(score_matrix)):\n                    if j==j_star:\n                        continue\n                    if j < j_star:\n                        probs = self.svms[f'{j}{j_star}'].predict_proba([test_sample])\n                        score_matrix[j][j_star] = probs[0][0]\n                        score_matrix[j_star][j] = probs[0][1]\n                    center_weight = (distance_to_centers[j_star])/(distance_to_centers[j_star] + distance_to_centers[j])\n                    KNN_weight = (avg_dist_to_KNN[j_star])/(avg_dist_to_KNN[j_star] + avg_dist_to_KNN[j])\n\n                    score_matrix[j][j_star] *= center_weight * KNN_weight\n            score_list = np.array([sum(score_matrix[j]) for j in range(len(score_matrix))])\n            predictions.append(np.argmax(score_list))\n\n        return np.array(predictions)\n\n    # calculates the squared distances\n    # The formula only uses the square of the distances\n    def __distance(self, point1, point2):\n        squared_distance = np.sum(np.square(point1-point2))\n        return squared_distance",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Test sklearn's toy datasets",
   "metadata": {
    "tags": [],
    "cell_id": "00003-780b4ca3-6bbe-4c30-bf40-d83bf17ca8bf",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Wine",
   "metadata": {
    "tags": [],
    "cell_id": "00004-64bfffe0-92af-48c1-ae43-fe20f4162452",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00004-d057df52-a19f-466a-a65a-f01a8eda184f",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "5ed0f307",
    "execution_start": 1641965684893,
    "execution_millis": 26,
    "deepnote_cell_type": "code"
   },
   "source": "wine = datasets.load_wine()\nX = wine.data\ny = wine.target\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00006-89c5bdbe-0789-4480-ad8f-52f052c4a43b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9b0c33d",
    "execution_start": 1641965684935,
    "execution_millis": 295,
    "deepnote_cell_type": "code"
   },
   "source": "testing_clf = ANNSVM(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 3), random_state=1)\ntesting_clf.fit(X_train, y_train)\npredictions = testing_clf.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))\nclf = svm.SVC(decision_function_shape='ovo', probability=True)\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))\nclf = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(13, 5), random_state=1)\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "[[14  0  0]\n [ 0 14  0]\n [ 0  0  8]]\n1.0\n[[14  0  0]\n [ 0 14  0]\n [ 0  0  8]]\n1.0\n[[14  0  0]\n [ 0 14  0]\n [ 0  0  8]]\n1.0\n",
     "output_type": "stream",
     "data": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00007-d72e87e6-2b51-4971-a98b-af9e3c04776d",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bc03a1f2",
    "execution_start": 1641965685239,
    "execution_millis": 252,
    "deepnote_cell_type": "code"
   },
   "source": "knnSvm = KNNSVM(K=5)\nknnSvm.fit(X_train, y_train)\npredictions = knnSvm.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "[[14  0  0]\n [ 0 14  0]\n [ 0  0  8]]\n1.0\n",
     "output_type": "stream",
     "data": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Iris",
   "metadata": {
    "tags": [],
    "cell_id": "00008-1f4cacd0-c44f-4518-b6d3-800bc3fb7cb9",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00009-a58b0951-58b1-4b06-9b11-1b8c9132861b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "18dc0034",
    "execution_start": 1641965685504,
    "execution_millis": 43,
    "deepnote_cell_type": "code"
   },
   "source": "iris = datasets.load_iris()\nX = iris.data\ny = iris.target\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00014-4fe58f3c-4982-4ca5-92ea-b2278c1f8201",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "e7d1137a",
    "execution_start": 1641965685547,
    "execution_millis": 777,
    "deepnote_cell_type": "code"
   },
   "source": "testing_clf = ANNSVM(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 3), random_state=1)\ntesting_clf.fit(X_train, y_train)\npredictions = testing_clf.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))\nclf = svm.SVC(decision_function_shape='ovo', probability=True)\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))\nclf = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(5, 4), random_state=1)\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "[[10  0  0]\n [ 0  9  0]\n [ 0  0 11]]\n1.0\n[[10  0  0]\n [ 0  9  0]\n [ 0  0 11]]\n1.0\n[[10  0  0]\n [ 0  9  0]\n [ 0  0 11]]\n1.0\n",
     "output_type": "stream",
     "data": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00010-946176aa-eb66-4658-86f6-b933a591ca39",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bc03a1f2",
    "execution_start": 1641965686039,
    "execution_millis": 287,
    "deepnote_cell_type": "code"
   },
   "source": "knnSvm = KNNSVM(K=5)\nknnSvm.fit(X_train, y_train)\npredictions = knnSvm.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "[[10  0  0]\n [ 0  9  0]\n [ 0  0 11]]\n1.0\n",
     "output_type": "stream",
     "data": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Breast Cancer",
   "metadata": {
    "tags": [],
    "cell_id": "00012-2e8f38ea-ec48-4a35-a1ae-6129c6480ba3",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00012-afa09bb2-79ff-43be-b0f0-fe830ffd6073",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7036712f",
    "execution_start": 1641966427702,
    "execution_millis": 46,
    "deepnote_cell_type": "code"
   },
   "source": "breast_cancer = datasets.load_breast_cancer()\nX = breast_cancer.data\ny = breast_cancer.target\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00014-c0ec4128-d7be-4490-b499-bf5fe6ebe76d",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "db03b285",
    "execution_start": 1641966488735,
    "execution_millis": 560,
    "deepnote_cell_type": "code"
   },
   "source": "testing_clf = ANNSVM(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 3), random_state=1)\ntesting_clf.fit(X_train, y_train)\npredictions = testing_clf.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))\nclf = svm.SVC(decision_function_shape='ovo', probability=True)\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))\nclf = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(30, 6), random_state=1)\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "[[41  2]\n [ 2 69]]\n0.9649122807017544\n[[41  2]\n [ 0 71]]\n0.9824561403508771\n[[42  1]\n [ 3 68]]\n0.9649122807017544\n",
     "output_type": "stream",
     "data": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00015-e782be25-1a18-4e29-857c-7db92956e4e4",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bc03a1f2",
    "execution_start": 1641965686878,
    "execution_millis": 1412,
    "deepnote_cell_type": "code"
   },
   "source": "knnSvm = KNNSVM(K=5)\nknnSvm.fit(X_train, y_train)\npredictions = knnSvm.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "[[41  2]\n [ 2 69]]\n0.9649122807017544\n",
     "output_type": "stream",
     "data": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Test external datasets",
   "metadata": {
    "tags": [],
    "cell_id": "00016-01848fec-912a-4eae-9e1b-f74beb1de8bc",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Ionosphere",
   "metadata": {
    "tags": [],
    "cell_id": "00007-76d6ac11-29da-4f7f-972c-1d83abdd2489",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00009-776a335a-83cd-4169-9d02-1e86550a453d",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "e3dfe9e6",
    "execution_start": 1641973794465,
    "execution_millis": 256,
    "deepnote_cell_type": "code"
   },
   "source": "ionosphere_df = pd.read_csv('ionosphere.data')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00009-ff64e71f-8c9f-406a-bf04-b5bf3dfe106a",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a3cb40cf",
    "execution_start": 1641965688543,
    "execution_millis": 6,
    "deepnote_cell_type": "code"
   },
   "source": "y = ionosphere_df.iloc[:, -1].to_numpy()\nX = ionosphere_df.iloc[:, :-1].to_numpy()\n\ny = np.array([(0 if value=='b' else 1) for value in y])\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00010-8500dedf-83fc-4601-919a-5867c996cd38",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d5a6437b",
    "execution_start": 1641965688560,
    "execution_millis": 356,
    "deepnote_cell_type": "code"
   },
   "source": "testing_clf = ANNSVM(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\ntesting_clf.fit(X_train, y_train)\npredictions = testing_clf.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))\nclf = svm.SVC(decision_function_shape=\"ovo\", probability=True)\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))\nclf = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(34, 6), random_state=1)\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))\n",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "[[23  3]\n [ 2 42]]\n0.9285714285714286\n[[20  6]\n [ 1 43]]\n0.9\n[[21  5]\n [ 1 43]]\n0.9142857142857143\n",
     "output_type": "stream",
     "data": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00011-59e58203-f069-4b56-ab61-92640b5bd10f",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bc03a1f2",
    "execution_start": 1641965688920,
    "execution_millis": 646,
    "deepnote_cell_type": "code"
   },
   "source": "knnSvm = KNNSVM(K=5)\nknnSvm.fit(X_train, y_train)\npredictions = knnSvm.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "[[22  4]\n [ 1 43]]\n0.9285714285714286\n",
     "output_type": "stream",
     "data": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Cardiotocorgraphy",
   "metadata": {
    "tags": [],
    "cell_id": "00022-9e79fbea-29ac-4bce-bae6-94aca7d46043",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00016-563e447f-8395-4149-aaba-3e602361811c",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4d6c4313",
    "execution_start": 1641965689569,
    "execution_millis": 21,
    "deepnote_cell_type": "code"
   },
   "source": "cardio_df = pd.read_csv('cardiotocography.csv')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00024-4aa168c8-d770-40ca-8dee-d7f9842bf90f",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9a81205",
    "execution_start": 1641965689597,
    "execution_millis": 9,
    "deepnote_cell_type": "code"
   },
   "source": "y = cardio_df.iloc[:, -1].to_numpy()-1\nX = cardio_df.iloc[:, :-1].to_numpy()\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00025-e786f914-d514-495b-b117-f0ca1696cfbf",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "1aabe1a4",
    "execution_start": 1641965689609,
    "execution_millis": 37907,
    "deepnote_cell_type": "code"
   },
   "source": "testing_clf = ANNSVM(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(50, 15), random_state=1)\ntesting_clf.fit(X_train, y_train)\npredictions = testing_clf.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))\nclf = svm.SVC(decision_function_shape='ovo', probability=True)\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))\nclf = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(35, 11), random_state=1)\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "[[ 73   0   0   0   0   0   0   0   0   0]\n [  0 113   0   0   0   0   1   0   0   0]\n [  0   0  13   0   0   0   0   0   0   0]\n [  0   0   0  19   0   0   0   0   0   0]\n [  0   0   0   0  17   0   0   0   0   0]\n [  0   0   0   0   0  63   0   0   0   0]\n [  0   0   0   0   0   0  54   0   0   0]\n [  0   0   0   0   0   0   0  16   0   0]\n [  0   0   0   0   0   0   0   0  12   0]\n [  0   0   0   0   0   0   0   0   0  45]]\n0.9976525821596244\n[[ 73   0   0   0   0   0   0   0   0   0]\n [  0 113   0   0   0   0   1   0   0   0]\n [  0   0  13   0   0   0   0   0   0   0]\n [  0   0   0  19   0   0   0   0   0   0]\n [  0   0   0   0  17   0   0   0   0   0]\n [  0   0   0   0   0  63   0   0   0   0]\n [  0   0   0   0   0   0  54   0   0   0]\n [  0   0   0   0   0   0   0  16   0   0]\n [  0   0   0   0   0   0   0   0  12   0]\n [  0   0   0   0   0   0   0   0   0  45]]\n0.9976525821596244\n[[ 73   0   0   0   0   0   0   0   0   0]\n [  0 113   0   0   0   1   0   0   0   0]\n [  0   0  13   0   0   0   0   0   0   0]\n [  0   0   0  19   0   0   0   0   0   0]\n [  0   0   0   0  17   0   0   0   0   0]\n [  0   0   0   0   0  63   0   0   0   0]\n [  0   0   0   0   0   0  54   0   0   0]\n [  0   0   0   0   0   0   0  16   0   0]\n [  0   0   0   0   0   0   0   0  12   0]\n [  0   0   0   0   0   0   0   0   0  45]]\n0.9976525821596244\n",
     "output_type": "stream",
     "data": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00026-ae087707-d44d-4300-803f-1322e8b388ff",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bc03a1f2",
    "execution_start": 1641965727522,
    "execution_millis": 26518,
    "deepnote_cell_type": "code"
   },
   "source": "knnSvm = KNNSVM(K=5)\nknnSvm.fit(X_train, y_train)\npredictions = knnSvm.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "[[ 73   0   0   0   0   0   0   0   0   0]\n [  0 113   0   0   0   0   1   0   0   0]\n [  0   0  13   0   0   0   0   0   0   0]\n [  0   0   0  19   0   0   0   0   0   0]\n [  0   0   0   0  17   0   0   0   0   0]\n [  0   0   0   0   0  63   0   0   0   0]\n [  0   0   0   0   0   0  54   0   0   0]\n [  0   0   0   0   0   0   0  16   0   0]\n [  0   0   0   0   0   0   0   0  12   0]\n [  0   0   0   0   0   0   0   0   0  45]]\n0.9976525821596244\n",
     "output_type": "stream",
     "data": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Optdigits",
   "metadata": {
    "tags": [],
    "cell_id": "00027-127b3529-edfc-42d4-82f2-a70a0f2b02ea",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00027-0e703ea1-4aed-48b4-9673-344bfefa920b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ecbfcd62",
    "execution_start": 1641965754064,
    "execution_millis": 69,
    "deepnote_cell_type": "code"
   },
   "source": "optdigits_df = pd.read_csv('optdigits.csv')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00029-40127f5d-2d7c-4f3e-bb12-2678cff18338",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "deeb68dd",
    "execution_start": 1641965754135,
    "execution_millis": 37,
    "deepnote_cell_type": "code"
   },
   "source": "y = optdigits_df.iloc[:, -1].to_numpy()\nX = optdigits_df.iloc[:, :-1].to_numpy()\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00030-4dcd9160-26ed-4454-8028-cde0dbbb178b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2f2b84e3",
    "execution_start": 1641965754183,
    "execution_millis": 123812,
    "deepnote_cell_type": "code"
   },
   "source": "testing_clf = ANNSVM(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(40, 15), random_state=1)\ntesting_clf.fit(X_train, y_train)\npredictions = testing_clf.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))\nclf = svm.SVC(decision_function_shape='ovo', probability=True)\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))\nclf = MLPClassifier(solver='adam', hidden_layer_sizes=(66, 13), random_state=1)\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "[[106   0   1   0   0   0   0   0   1   0]\n [  0 100   0   0   0   0   0   0   0   2]\n [  0   0 105   0   1   0   0   0   0   1]\n [  0   0   0 112   0   6   0   0   0   0]\n [  0   0   0   0 116   0   1   0   0   0]\n [  0   0   0   0   0  96   0   0   1   0]\n [  0   1   0   0   0   0 122   0   0   0]\n [  0   0   0   0   0   0   0 123   0   1]\n [  0   0   0   0   2   0   0   0 103   0]\n [  0   1   0   2   0   0   0   0   2 118]]\n0.9795373665480427\n[[108   0   0   0   0   0   0   0   0   0]\n [  0 102   0   0   0   0   0   0   0   0]\n [  0   0 106   0   1   0   0   0   0   0]\n [  0   0   0 115   0   3   0   0   0   0]\n [  0   0   0   0 116   0   1   0   0   0]\n [  0   0   0   0   0  97   0   0   0   0]\n [  0   1   0   0   0   0 122   0   0   0]\n [  0   0   0   0   0   0   0 123   0   1]\n [  0   0   0   0   2   0   0   0 103   0]\n [  0   1   0   2   0   0   0   0   1 119]]\n0.9884341637010676\n[[108   0   0   0   0   0   0   0   0   0]\n [  0 100   0   0   0   0   0   0   2   0]\n [  0   0 104   1   0   1   0   1   0   0]\n [  0   0   0 115   0   3   0   0   0   0]\n [  0   0   0   0 114   0   0   0   0   3]\n [  0   0   0   1   1  92   0   0   0   3]\n [  0   1   0   0   1   1 120   0   0   0]\n [  0   0   0   0   0   0   0 124   0   0]\n [  0   2   0   0   1   0   0   0 102   0]\n [  0   0   0   3   0   1   0   0   2 117]]\n0.9750889679715302\n",
     "output_type": "stream",
     "data": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00031-ad92102c-95fc-4acd-a056-bdff2e8fd85d",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "62d9e0a5",
    "execution_start": 1641965878005,
    "execution_millis": 148355,
    "deepnote_cell_type": "code"
   },
   "source": "knnSvm = KNNSVM(K=1)\nknnSvm.fit(X_train, y_train)\npredictions = knnSvm.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "[[108   0   0   0   0   0   0   0   0   0]\n [  0 101   0   0   0   0   0   0   1   0]\n [  0   1 103   0   0   0   0   0   2   1]\n [  0   0   0 115   0   2   0   0   0   1]\n [  0   0   0   0 115   0   1   0   0   1]\n [  0   0   0   0   0  96   0   0   0   1]\n [  0   1   0   0   0   0 122   0   0   0]\n [  0   0   0   0   0   0   0 124   0   0]\n [  0   2   1   0   0   1   0   0 101   0]\n [  0   1   0   2   1   0   0   1   2 116]]\n0.9795373665480427\n",
     "output_type": "stream",
     "data": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Micro-mass",
   "metadata": {
    "tags": [],
    "cell_id": "00032-914d4304-723d-410a-b390-c2ac0cef89cc",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00032-606f5ef3-1877-4ddc-900b-2fdc38572848",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "e59f6fbd",
    "execution_start": 1641966026360,
    "execution_millis": 490,
    "deepnote_cell_type": "code"
   },
   "source": "micromass_df = pd.read_csv('micro-mass.csv')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00034-96bf2b30-8f5c-4501-9f27-19601d4d6351",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ac318549",
    "execution_start": 1641966026867,
    "execution_millis": 45,
    "deepnote_cell_type": "code"
   },
   "source": "y = micromass_df.iloc[:, -1].to_numpy() - 1\nX = micromass_df.iloc[:, :-1].to_numpy()\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00035-a933ea01-3b10-48f7-a45c-4772e13d5320",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "11c535c0",
    "execution_start": 1641966026931,
    "execution_millis": 66401,
    "deepnote_cell_type": "code"
   },
   "source": "testing_clf = ANNSVM(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(200, 30), random_state=1)\ntesting_clf.fit(X_train, y_train)\npredictions = testing_clf.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))\nclf = svm.SVC(decision_function_shape='ovo', probability=True)\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))\nclf = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(163, 21), random_state=1)\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "[[8 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 4 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n [0 0 9 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n [0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 3 1 0 0 0 0 0 0 1 0 0 0 0 0]\n [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 1 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 2 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 2 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 1 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0]\n [0 0 0 0 2 0 0 0 0 0 2 0 3 0 0 0 0 0 0 1]\n [0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1]\n [0 0 0 0 1 0 0 0 0 0 0 0 0 0 3 0 0 1 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n [0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 9 1 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 6 0 0]\n [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0]\n [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7]]\n0.6782608695652174\n[[ 8  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n [ 0  2  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2]\n [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0]\n [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0]\n [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0]\n [ 0  0  1  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  3  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0]\n [ 0  0  2  0  0  0  0  0  5  0  0  0  0  0  0  0  0  0  0  0]\n [ 0  0  2  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0]\n [ 0  0  2  0  0  0  0  0  0  0  3  0  0  0  0  0  1  0  0  0]\n [ 0  0  2  0  0  0  0  0  0  0  0  2  0  0  0  0  1  0  0  0]\n [ 0  0  3  0  0  0  0  0  0  0  0  0  4  0  0  0  1  0  0  0]\n [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0]\n [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  3  0  1  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  0  0  0]\n [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  4  0  0]\n [ 0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0]\n [ 0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  3]]\n0.5565217391304348\n[[10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n [ 0  5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0]\n [ 0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n [ 0  0  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n [ 0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n [ 0  0  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  2  1  0  0  0  0  0  0  0  0  1  0  0  1]\n [ 0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0]\n [ 0  0  0  1  0  0  0  0  6  0  0  0  0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  1  4  0  0  0  0  0  0  0  0  0  0]\n [ 0  0  0  1  0  0  0  0  0  0  4  0  1  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  5  0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  1  0  7  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  0  2  0  0  0]\n [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0  1  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  3  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  7]]\n0.8173913043478261\n",
     "output_type": "stream",
     "data": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00036-b7763bd4-1e58-4afa-9b90-368f88bab885",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "62d9e0a5",
    "execution_start": 1641966093333,
    "execution_millis": 16911,
    "deepnote_cell_type": "code"
   },
   "source": "knnSvm = KNNSVM(K=1)\nknnSvm.fit(X_train, y_train)\npredictions = knnSvm.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "[[ 8  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n [ 0  4  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  1]\n [ 0  0  9  0  0  1  0  0  0  0  0  0  0  0  0  0  1  0  0  0]\n [ 0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0]\n [ 0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  3  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0]\n [ 0  0  0  0  0  1  0  0  6  0  0  0  0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  2  0  0  0  3  0  0  0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  2  0  0  0  0  4  0  0  0  0  0  0  0  0  0]\n [ 0  0  0  0  0  1  0  0  0  0  0  3  0  0  0  0  1  0  0  0]\n [ 0  0  0  0  0  2  0  0  0  0  2  0  3  0  0  0  0  1  0  0]\n [ 0  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  2  0  0  0]\n [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0  3  0  1  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0]\n [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0 11  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  4  0  0]\n [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  2  0]\n [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  2  0  0  5]]\n0.6695652173913044\n",
     "output_type": "stream",
     "data": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Satimage",
   "metadata": {
    "tags": [],
    "cell_id": "00037-c3b9ca99-4528-4122-ba44-92f69ff4d451",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00038-f852d3e6-bd60-4254-99ff-627c5f1399ff",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "beee9b1f",
    "execution_start": 1641966110243,
    "execution_millis": 259,
    "deepnote_cell_type": "code"
   },
   "source": "satimage_df = pd.read_csv('satimage.csv')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00039-d1e5c7be-0bf5-46df-9947-9b051a2c3d42",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "65feb86",
    "execution_start": 1641966553014,
    "execution_millis": 63,
    "deepnote_cell_type": "code"
   },
   "source": "y = (satimage_df.iloc[:, -1].to_numpy() - 1).astype(int)\nX = satimage_df.iloc[:, :-1].to_numpy()\n\nunique, counts = np.unique(y, return_counts=True)\n#print(np.asarray((unique, counts)).T)\nnew_y = []\nfor i in range(len(y)):\n    new_y.append(np.where(unique == y[i])[0][0])\ny = np.array(new_y)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00040-986c4d1c-8acf-4995-a22a-77a80089787d",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4dc4aefb",
    "execution_start": 1641966627656,
    "execution_millis": 85073,
    "deepnote_cell_type": "code"
   },
   "source": "testing_clf = ANNSVM(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(17, 10), random_state=1)\ntesting_clf.fit(X_train, y_train)\npredictions = testing_clf.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))\nclf = svm.SVC(decision_function_shape='ovo', probability=True)\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))\nclf = MLPClassifier(solver='adam', hidden_layer_sizes=(38, 10), random_state=1)\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "text": "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\n  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n[[286   0   1   0   2   0]\n [  0 156   0   1   3   0]\n [  0   0 252  10   0   8]\n [  1   1  17  98   1  21]\n [  4   0   0   2 122   8]\n [  0   0   4  12   6 270]]\n0.9206842923794712\n[[286   1   0   0   2   0]\n [  0 157   0   1   2   0]\n [  1   0 259   7   0   3]\n [  1   1  24  84   1  28]\n [  8   0   0   2 115  11]\n [  0   0   7  19   3 263]]\n0.9051321928460342\n[[281   0   1   0   6   1]\n [  0 157   0   2   1   0]\n [  2   0 247  15   0   6]\n [  1   1  15 103   1  18]\n [  3   2   0   2 122   7]\n [  0   0   2  16   9 265]]\n0.9136858475894246\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n  ConvergenceWarning,\n",
     "output_type": "stream",
     "data": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00041-0495adfc-7a6b-4c13-83b1-bfc6d7999495",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "62d9e0a5",
    "execution_start": 1641966183289,
    "execution_millis": 170265,
    "deepnote_cell_type": "code"
   },
   "source": "knnSvm = KNNSVM(K=1)\nknnSvm.fit(X_train, y_train)\npredictions = knnSvm.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "[[257   1   1   0  30   0]\n [  0 153   1   2   4   0]\n [  1   0 249  18   0   2]\n [  1   0  15 101   1  21]\n [ 12   0   0   3 111  10]\n [  0   0   5  31   5 251]]\n0.8724727838258165\n",
     "output_type": "stream",
     "data": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Baseball",
   "metadata": {
    "tags": [],
    "cell_id": "00041-74c7197c-4a21-444a-8f71-0a9b1bdf76fd",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00042-31e00fea-0227-4f61-9128-6cd5cdc43313",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "f1155d6c",
    "execution_start": 1641966780174,
    "execution_millis": 28,
    "deepnote_cell_type": "code"
   },
   "source": "baseball_df = pd.read_csv('baseball.csv')\nbaseball_df = baseball_df.replace(to_replace='?', value=np.nan).dropna()\nbaseball_df = baseball_df.drop(columns='Player')\nbaseball_df.Position = pd.factorize(baseball_df['Position'])[0]",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00043-159d43e4-d05d-4835-ae9a-357995cdf77b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "405713fe",
    "execution_start": 1641966795741,
    "execution_millis": 17,
    "deepnote_cell_type": "code"
   },
   "source": "y = baseball_df.iloc[:, -1].to_numpy()\nX = baseball_df.iloc[:, :-1].to_numpy()\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00044-ee90d628-a22b-4990-ab8a-ad47022d22c0",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "feecd1e6",
    "execution_start": 1641966833257,
    "execution_millis": 4542,
    "deepnote_cell_type": "code"
   },
   "source": "testing_clf = ANNSVM(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 3), random_state=1)\ntesting_clf.fit(X_train, y_train)\npredictions = testing_clf.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))\nclf = svm.SVC(decision_function_shape='ovo', probability=True)\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))\nclf = MLPClassifier(solver='adam', hidden_layer_sizes=(18, 7), random_state=1)\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "text": "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\n  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n[[240   1   6]\n [  3   5   3]\n [  4   0   2]]\n0.9356060606060606\n[[245   1   1]\n [  5   4   2]\n [  4   0   2]]\n0.9507575757575758\n[[243   0   4]\n [  4   5   2]\n [  4   0   2]]\n0.946969696969697\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n  ConvergenceWarning,\n",
     "output_type": "stream",
     "data": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00045-0af060dc-3f2b-4e76-bb37-724f32815e08",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4de88044",
    "execution_start": 1641966358027,
    "execution_millis": 7722,
    "deepnote_cell_type": "code"
   },
   "source": "knnSvm = KNNSVM(K=10)\nknnSvm.fit(X_train, y_train)\npredictions = knnSvm.predict(X_test)\nprint(confusion_matrix(y_test, predictions))\nprint(np.sum(predictions == y_test)/len(X_test))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "[[239   3   5]\n [  4   5   2]\n [  3   0   3]]\n0.9356060606060606\n",
     "output_type": "stream",
     "data": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=8bc411b3-266f-4c53-919c-c65df1fc43dc' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "e64ee0fc-e903-4dea-a753-2484c001de88",
  "deepnote_execution_queue": []
 }
}